{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vae_by_mipt.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOnTLJbDPz+s/AjnJANtalo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlbertFarkhutdinov/ml_lessons/blob/main/vae_by_mipt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0B_E-IJUASzL"
      },
      "source": [
        "# Variational Autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNVc5cANA9Bd"
      },
      "source": [
        "**Setup**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjA-0XCOADle"
      },
      "source": [
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchsummary import summary\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "from tqdm.notebook import tqdm, trange"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxvKtG7xixrI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "401af99d-e8e7-4d74-b690-7fe03cbbf3fb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tA4N_5k97q7e"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "plt.style.use('seaborn')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "po40Qqnj_Pet",
        "outputId": "166d5bd7-f423-4a62-c16f-c953bd8bfb25"
      },
      "source": [
        "DATA_DIR = os.path.join(os.getcwd(), 'drive', 'My Drive', 'Colab Notebooks', 'data')\n",
        "DATA_DIR"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/Colab Notebooks/data'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CC3oa7ZVBKSa"
      },
      "source": [
        "**The device on which a torch.Tensor will be allocated.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlmnXQhQ77t8",
        "outputId": "32ba4def-5439-4aaf-e53e-62c40d374610"
      },
      "source": [
        "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
        "device"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRpgBsgdZNMo"
      },
      "source": [
        "**Tensor transformations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61X0ovSxU-Bt"
      },
      "source": [
        "def rescale(image):\n",
        "  image = image - image.min()\n",
        "  image = image / image.max()\n",
        "  return image"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJjtjVjeXE4e"
      },
      "source": [
        "mnist_transformations = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    rescale,\n",
        "])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COMZrnaPXA7J"
      },
      "source": [
        "BATCH_SIZE = 256\n",
        "NUM_DATALOADER_WORKERS = 1"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPmu4FsXX1DV"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset=MNIST(\n",
        "        root=DATA_DIR,\n",
        "        train=True,\n",
        "        transform=mnist_transformations,\n",
        "        download=True,\n",
        "    ),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=NUM_DATALOADER_WORKERS,\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoWFlVDUcJNL"
      },
      "source": [
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset=MNIST(\n",
        "        root=DATA_DIR,\n",
        "        train=False,\n",
        "        transform=mnist_transformations,\n",
        "    ),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_DATALOADER_WORKERS,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I256ezOyjAeA"
      },
      "source": [
        "class Encoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFrHUSEEjBWV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceDM_XM_ef0e"
      },
      "source": [
        "class VariationalAutoEncoder(nn.Module):\n",
        "    def __init__(self, intermediate_dims, latent_dim, input_shape):\n",
        "        super().__init__()\n",
        "        self.register_buffer('_initial_mu', torch.zeros((latent_dim)))\n",
        "        self.register_buffer('_initial_sigma', torch.ones((latent_dim)))\n",
        "\n",
        "        self.latent_distribution = torch.distributions.normal.Normal(\n",
        "            loc=self._initial_mu,\n",
        "            scale=self._initial_sigma\n",
        "        )\n",
        "        input_dim = np.prod(input_shape)\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(input_dim, intermediate_dims[0]),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(intermediate_dims[0]),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(intermediate_dims[0], intermediate_dims[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(intermediate_dims[1]),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        \n",
        "        self.mu_repr = nn.Linear(intermediate_dims[1], latent_dim)\n",
        "        self.log_sigma_repr = nn.Linear(intermediate_dims[1], latent_dim)  \n",
        "        \n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, intermediate_dims[1]),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.BatchNorm1d(intermediate_dims[1]),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(intermediate_dims[1], intermediate_dims[0]),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.BatchNorm1d(intermediate_dims[0]),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(intermediate_dims[0], input_dim),\n",
        "            nn.Sigmoid(),\n",
        "            RestoreShape(input_shape)\n",
        "        )\n",
        "    \n",
        "    def _encode(self, x):\n",
        "        latent_repr = self.encoder(x)\n",
        "        mu_values = self.mu_repr(latent_repr)\n",
        "        log_sigma_values = self.log_sigma_repr(latent_repr)\n",
        "        return mu_values, log_sigma_values, latent_repr\n",
        "    \n",
        "    def _reparametrize(self, sample, mu_values, log_sigma_values):\n",
        "        latent_sample = torch.exp(log_sigma_values) * sample + mu_values\n",
        "        return latent_sample\n",
        "\n",
        "    def forward(self, x, raw_sample=None):\n",
        "        mu_values, log_sigma_values, latent_repr = self._encode(x)\n",
        "\n",
        "        if raw_sample is None:\n",
        "            raw_sample = torch.randn_like(mu_values)\n",
        "\n",
        "        latent_sample = self._reparametrize(raw_sample, mu_values, log_sigma_values)\n",
        "        \n",
        "        reconstructed_repr = self.decoder(latent_sample)\n",
        "        \n",
        "        return reconstructed_repr, latent_sample, mu_values, log_sigma_values"
      ],
      "execution_count": 17,
      "outputs": []
    }
  ]
}